{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZnLIxqgNx2r5ctWe03OpS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmiharikumar/deeplearning/blob/main/nlp_fundamentals_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to NLP"
      ],
      "metadata": {
        "id": "1PT2Uxmgvl9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nilTig6GVkQJ",
        "outputId": "8c2ea71b-7a9e-4de1-a6f5-fef104bcc77f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 22:24:36--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.253.123.128, 142.250.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-26 22:24:36 (55.4 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file = zipfile.ZipFile(\"nlp_getting_started.zip\")\n",
        "zip_file.extractall()\n",
        "zip_file.close()"
      ],
      "metadata": {
        "id": "sxUo6LRUWLJd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualize the data\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n"
      ],
      "metadata": {
        "id": "v4qr2hWtXL2a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "o0hWr1z5ZvVi",
        "outputId": "5163bcb1-6db0-4398-b74b-c17df396ba83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-232214c9-2194-4af7-873e-072a6c6a6427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-232214c9-2194-4af7-873e-072a6c6a6427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-232214c9-2194-4af7-873e-072a6c6a6427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-232214c9-2194-4af7-873e-072a6c6a6427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many examples of each target\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqQbwW6aR_V",
        "outputId": "de886376-1501-47e7-b576-f770baafeb4d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets visualize some code\n",
        "import random\n",
        "\n",
        "# random.seed(42)\n",
        "random_index = random.randint(0, len(train_df_shuffled)-5)\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real_disaster)\" if target > 0 else \"(not a real disaster)\")\n",
        "  print(f\"Text is: {text}\")\n",
        "  print(\"------------------\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j2q3BaDPSpw",
        "outputId": "a904d47c-d6fd-4fae-d8fa-301d076004e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 (not a real disaster)\n",
            "Text is: I liked a @YouTube video http://t.co/45TWHJ0l6m RomanAtwoodVlogs | RESCUED SICK KITTENS!!\n",
            "------------------\n",
            "\n",
            "Target: 1 (real_disaster)\n",
            "Text is: #Bestnaijamade: 16yr old PKK suicide bomber who detonated bomb in ... http://t.co/KSAwlYuX02 bestnaijamade bestnaijamade bestnaijamade beÛ_\n",
            "------------------\n",
            "\n",
            "Target: 0 (not a real disaster)\n",
            "Text is: @YoungHeroesID 4. Lava Blast Power Red #PantherAttack\n",
            "------------------\n",
            "\n",
            "Target: 1 (real_disaster)\n",
            "Text is: Central Mass. fruit trees escape heavy damage after wind hail http://t.co/VbFfodtP6M\n",
            "------------------\n",
            "\n",
            "Target: 1 (real_disaster)\n",
            "Text is: As of 2010 there were 17 Beluga deaths reported at #SeaWorld their average age 15 1/2 years #OpSeaWorld http://t.co/MZk5UjlFCV\n",
            "------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Xt2hh__FdC1K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "metadata": {
        "id": "MfcctF6GeAKz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXa2kjRQfuMm",
        "outputId": "51801d88-0ece-445e-9b1f-d7483cea180d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Text to Numbers\n",
        "\n",
        "1. Tokenization\n",
        "2. Embedding"
      ],
      "metadata": {
        "id": "IfjA1O-j-NXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "SoJg0lh6HPpn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=None,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be\n",
        "                                    pad_to_max_tokens=False)"
      ],
      "metadata": {
        "id": "C-GlJmgwHYek"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average number of words in a sentence\n",
        "max_length = 0;\n",
        "for i in train_sentences:\n",
        "  max_length = max_length + len(i)\n",
        "max_length = max_length / len(train_sentences)\n",
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1SMoMA9I_xs",
        "outputId": "6f223d4c-292b-4552-d966-2046beebbe49"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.84294263611152"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(sum([len(i.split()) for i in train_sentences]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcqEWCN2Kzka",
        "outputId": "49f9dacd-17d3-4a3b-c6c9-0ffc930c8f45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102087"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 10000\n",
        "max_length = round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))\n",
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhNGtarGL4Cj",
        "outputId": "bb71923d-3b17-4826-ebf7-c0be2a7e703d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length,\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "metadata": {
        "id": "r026dumiN_lm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the train sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "40MLwEnDOrTC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence=\"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HpSrKSXPJNf",
        "outputId": "deadbb42-9691-4d42-e74b-cb2e07c858b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## See top 5 and bottom 5 words \n",
        "all_words = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words: {len(all_words)}\")\n",
        "print(f\"Top 5 words: {all_words[:5]}\")\n",
        "print(f\"Bottom 5 words: {all_words[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ABHLrSVTVN3",
        "outputId": "feaa9619-2af3-426e-fac7-b63bf30ed838"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words: 10000\n",
            "Top 5 words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "To create an embedding we use Tensorflow's Embedding layer\n",
        "\n",
        "Parameters\n",
        "* `input_dim` - size of vocab (10000)\n",
        "* `output_dim` - size of each output embedding vector\n",
        "* `input_length` - length of sequences being passed to embedding layer (15) "
      ],
      "metadata": {
        "id": "3L_sfO9IUl_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = tf.keras.layers.Embedding(input_dim = max_vocab_length,\n",
        "                                      output_dim = 128,\n",
        "                                      input_length = max_length)"
      ],
      "metadata": {
        "id": "vR1DhJ6aU4no"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = random.choice(train_sentences)\n",
        "print(f\"The sentence is: {sample_sentence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VcEzOskZ9-e",
        "outputId": "3ea72469-d9a8-4667-ab7f-9e81e6fe02dd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence is: Still no plans? Don't worry we got you covered. Plenty of Seismic IPA and Seismic Squeeze Radler to help... http://t.co/A8nMdkd3rV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_op = embedding(text_vectorizer([sample_sentence]))\n",
        "embed_op"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk7-BEraaRTU",
        "outputId": "018d549a-dce2-48cb-857e-bd9cabfc7ead"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04135367, -0.04297298,  0.01889981, ..., -0.00715023,\n",
              "          0.02596622,  0.01632125],\n",
              "        [ 0.01815074, -0.00092636, -0.01173472, ...,  0.017931  ,\n",
              "          0.02832935, -0.00241455],\n",
              "        [ 0.03333833, -0.00031959,  0.00850451, ...,  0.00495659,\n",
              "         -0.03048179,  0.03254688],\n",
              "        ...,\n",
              "        [-0.03757721,  0.0112638 ,  0.01497832, ...,  0.00176647,\n",
              "         -0.01097985, -0.00880669],\n",
              "        [-0.03309876, -0.00781668, -0.02436919, ...,  0.00317317,\n",
              "          0.03854719,  0.0057398 ],\n",
              "        [ 0.00827412,  0.00477184,  0.03447337, ..., -0.00939039,\n",
              "         -0.00980262, -0.04778599]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0 - Baseline model with scikit - Text Classification with Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "_9ljkioCPl8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer ## Convert text to numbers\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "f_temKvPQtzh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tokenization and modeling pipeline\n",
        "model_0 = Pipeline([\n",
        "                  (\"tfidf\", TfidfVectorizer()),\n",
        "                  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkDcJRufRSHV",
        "outputId": "9ae27ab0-b5cc-4c85-d2a9-b731b86af209"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate out baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"The score of baseline model is: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KywvzrI6SnrZ",
        "outputId": "15d1ffb6-00c3-4dd2-cebe-5e44a1389aa8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score of baseline model is: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "print(f\"Baseline model predictions: {baseline_preds[:10]}\")\n",
        "print(f\"Actual values: {val_labels[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ooWIcHTQUg",
        "outputId": "55a154b2-96ed-4823-f4ca-4f59e07b32f7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model predictions: [1 1 1 0 0 1 1 1 1 0]\n",
            "Actual values: [0 0 1 1 1 1 1 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that returns evaluation metrics\n",
        "from sklearn import metrics\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  eval_metrics = {}\n",
        "  eval_metrics[\"accuracy\"] = metrics.accuracy_score(y_true, y_pred) * 100\n",
        "  eval_metrics[\"precision\"] = metrics.precision_score(y_true, y_pred) * 100\n",
        "  eval_metrics[\"recall\"] = metrics.recall_score(y_true, y_pred) * 100\n",
        "  eval_metrics[\"f1_score\"] = metrics.f1_score(y_true, y_pred) * 100\n",
        "\n",
        "  return eval_metrics"
      ],
      "metadata": {
        "id": "HIY8mpPlUUGj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8R10-lZj2-d",
        "outputId": "40ea3b64-d868-4dfa-c9f0-7fbbb3e3b2b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 88.6178861788618,\n",
              " 'recall': 62.643678160919535,\n",
              " 'f1_score': 73.4006734006734}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1 - Feed forward neural network (A simple dense model)"
      ],
      "metadata": {
        "id": "HKx9zvkplWiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "veI_FaBgoQ8k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "YrgfWH_Dlz9O"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model using functional API\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x) # Condense the feature vector for each tokento one vector\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs,outputs, name=\"model_1_dense\")"
      ],
      "metadata": {
        "id": "7dxpPwO_o1DO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Txj1C3HpfD",
        "outputId": "33075227-05a8-485e-ecec-0ff2768d21aa"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "sVstrLSFH6We"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")]\n",
        "                        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRjXH7pLIPfo",
        "outputId": "4f7e8834-b78d-456d-cf4b-5c43f74c9209"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20230126-222450\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 48ms/step - loss: 0.6138 - accuracy: 0.6869 - val_loss: 0.5384 - val_accuracy: 0.7559\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.4446 - accuracy: 0.8183 - val_loss: 0.4724 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 25ms/step - loss: 0.3485 - accuracy: 0.8596 - val_loss: 0.4575 - val_accuracy: 0.7927\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.2856 - accuracy: 0.8904 - val_loss: 0.4607 - val_accuracy: 0.7900\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.2385 - accuracy: 0.9104 - val_loss: 0.4776 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQUc0htXLrL5",
        "outputId": "a98d83df-8e9b-44b5-f34a-afeac2756052"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47762688994407654, 0.7860892415046692]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_preds = model_1.predict(val_sentences)\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h8l-FdIMTlQ",
        "outputId": "76b793b6-a93a-4b3a-f609-87e9d77e8dde"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39852282],\n",
              "       [0.761952  ],\n",
              "       [0.9976947 ],\n",
              "       [0.09993853],\n",
              "       [0.10411252],\n",
              "       [0.94020826],\n",
              "       [0.9136869 ],\n",
              "       [0.99409026],\n",
              "       [0.9643234 ],\n",
              "       [0.21410784]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model prediction probabilities into labels\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_preds))"
      ],
      "metadata": {
        "id": "paQOOHCYMmdC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ccp99dTMKXZ",
        "outputId": "dba03b5a-61da-4bf1-bf82-fd728c3952a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.60892388451444,\n",
              " 'precision': 82.45614035087719,\n",
              " 'recall': 67.52873563218391,\n",
              " 'f1_score': 74.24960505529226}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SIbcJsgM3YE",
        "outputId": "2d35568e-e5a0-4da6-817c-e92255088310"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 88.6178861788618,\n",
              " 'recall': 62.643678160919535,\n",
              " 'f1_score': 73.4006734006734}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaD0VyFaR0xN",
        "outputId": "0059c64f-a8d6-49e2-8079-0ab8465d77e2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# these are the numerical representations of each token in our training data, which have been learned for 5 epochs\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape # same as vocab size and embedding dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1u-kVTYR56Q",
        "outputId": "e199a2b6-948d-41b3-950d-192a4552300e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNs\n",
        "\n",
        "Premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input\n",
        "\n",
        "To Read\n",
        "1. MIT's sequence modelling lecture\n",
        "2. Chris Olah's intro to LSTM\n",
        "3. word2vec\n",
        "4. Word Embeddings\n",
        "5. Unreasonable effectiveness of RNNs"
      ],
      "metadata": {
        "id": "_bn4dhl8S_Cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 - LSTM\n",
        "\n",
        "Long Short Term Memory \n",
        "\n",
        "Structure of an RNN \n",
        "- Input (text) -> Tokenize -> Embedding-> Layers (RNNs/dense) ->  Output (label probability)"
      ],
      "metadata": {
        "id": "UO8D_SL_WDcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model using functional API\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(f\"After emedding the shape is: {x.shape}\")\n",
        "# x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x) # when you stack LSTM layers you need to return sequences\n",
        "# print(f\"After first LSTM the shape is: {x.shape}\")\n",
        "x = tf.keras.layers.LSTM(64)(x)\n",
        "print(f\"After second LSTM shape is: {x.shape}\")\n",
        "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_lstm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvfdabirW_Ek",
        "outputId": "b887f435-61cb-42f1-847a-c70fff413778"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After emedding the shape is: (None, 15, 128)\n",
            "After second LSTM shape is: (None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtByrzfHcwzl",
        "outputId": "22c4e17b-5c5d-4a38-eae0-71e3604a52ef"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mm0Wb9nxc8vO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_2_lstm\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qbrTUBYdWCW",
        "outputId": "bf45280d-4deb-4472-ad45-c19e13c4b372"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_lstm/20230126-222536\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 16s 53ms/step - loss: 0.2258 - accuracy: 0.9180 - val_loss: 0.5833 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.1557 - accuracy: 0.9419 - val_loss: 0.6408 - val_accuracy: 0.7900\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 10s 45ms/step - loss: 0.1245 - accuracy: 0.9524 - val_loss: 0.7217 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.1029 - accuracy: 0.9604 - val_loss: 0.8108 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 6s 27ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 1.1849 - val_accuracy: 0.7769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model 2\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL2CXJiDeRXB",
        "outputId": "5248058f-2a55-4f78-b28d-f5ebffd6a55f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.0613466e-04],\n",
              "       [5.5498362e-01],\n",
              "       [9.9990100e-01],\n",
              "       [1.1658367e-02],\n",
              "       [1.6974936e-04],\n",
              "       [9.9974692e-01],\n",
              "       [7.3307854e-01],\n",
              "       [9.9993640e-01],\n",
              "       [9.9988067e-01],\n",
              "       [2.5762850e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probabilities to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW4TfSHse5A2",
        "outputId": "b3133144-55d1-4836-9420-0992813c9aae"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipotBFX9fNaX",
        "outputId": "ecfa25f5-a9f1-4dcf-e7f2-1f5e575b64d9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.69028871391076,\n",
              " 'precision': 82.2463768115942,\n",
              " 'recall': 65.22988505747126,\n",
              " 'f1_score': 72.75641025641025}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3 - RNN using GRU\n",
        "\n",
        "Gated Recurrent Unit\n",
        "\n",
        "GRU cell has similar features to LSTM but has lower number of parameters"
      ],
      "metadata": {
        "id": "-ku_mZ0vfsHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build using functional API\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.GRU(units=64)(x)\n",
        "outputs=tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_gru\")"
      ],
      "metadata": {
        "id": "X6EoCm5_fq5Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model summary\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zCXb0WJn3-J",
        "outputId": "47465575-8aaa-4cea-b527-9c4ee08d05cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_gru\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Blo0189kn8H-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                    experiment_name=\"model_3_gru\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9f4GMZFoN0u",
        "outputId": "5d33c26a-ab9e-47f8-b5ca-66ec7a7c1ee5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_gru/20230126-222628\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 13s 49ms/step - loss: 0.1510 - accuracy: 0.9434 - val_loss: 0.6997 - val_accuracy: 0.7756\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 11s 49ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.8947 - val_accuracy: 0.7795\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0708 - accuracy: 0.9731 - val_loss: 0.8337 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0595 - accuracy: 0.9758 - val_loss: 1.0987 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 10s 44ms/step - loss: 0.0595 - accuracy: 0.9737 - val_loss: 1.2193 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predictions\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skwm9pSopOIM",
        "outputId": "08c7ef72-9fee-49f8-ee05-9af7b8579d10"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 2s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.38045279e-02],\n",
              "       [7.74851263e-01],\n",
              "       [9.99916553e-01],\n",
              "       [1.21154204e-01],\n",
              "       [4.38189090e-05],\n",
              "       [9.99813437e-01],\n",
              "       [4.04991269e-01],\n",
              "       [9.99970734e-01],\n",
              "       [9.99950349e-01],\n",
              "       [6.74697638e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probabilities to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ_qY8pRpisi",
        "outputId": "ed0e939b-fd35-4e47-acf3-4e7113f63209"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model_3 results\n",
        "model_3_results = calculate_results(val_labels, model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZsAYXEvp-bz",
        "outputId": "59766cdc-144d-48a3-b142-364f9510e027"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'precision': 78.47682119205298,\n",
              " 'recall': 68.10344827586206,\n",
              " 'f1_score': 72.92307692307692}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNNs go from left to right. However bidirectional RNN goes from left to right and right to left"
      ],
      "metadata": {
        "id": "Htjp72j3JzR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a bidirectional RNN in tensorflow\n",
        "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64))(x)\n",
        "# x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x)\n",
        "outputs=tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "metadata": {
        "id": "SiGfN4q3KCcs"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model summary\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shQtMYXtMhRF",
        "outputId": "58f1c3f3-c8af-403e-95cf-cf652d31fbea"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "anSfjd2GNPY3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_4_bidirectional\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAWylu5jNefG",
        "outputId": "a75f3ca1-53eb-4a8d-e099-3de3cbb9d50b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20230126-223419\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 42ms/step - loss: 0.1005 - accuracy: 0.9704 - val_loss: 0.9457 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 12s 54ms/step - loss: 0.0522 - accuracy: 0.9769 - val_loss: 1.2773 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 14s 66ms/step - loss: 0.0459 - accuracy: 0.9790 - val_loss: 1.4004 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 15s 68ms/step - loss: 0.0427 - accuracy: 0.9807 - val_loss: 1.3730 - val_accuracy: 0.7612\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 14s 65ms/step - loss: 0.0426 - accuracy: 0.9809 - val_loss: 1.2630 - val_accuracy: 0.7625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NWc2vG7MoGE",
        "outputId": "d060cd0e-692c-4acd-dac8-033650f75845"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.6787204e-02],\n",
              "       [9.2426914e-01],\n",
              "       [9.9993420e-01],\n",
              "       [1.0841317e-01],\n",
              "       [2.7345560e-04],\n",
              "       [9.9959606e-01],\n",
              "       [9.4492507e-01],\n",
              "       [9.9997598e-01],\n",
              "       [9.9995643e-01],\n",
              "       [9.2648071e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs into labels\n",
        "model_4_pred = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEn3TCu6Mp-J",
        "outputId": "465d2315-ce21-4167-de15-72ded4804509"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_4_results = calculate_results(val_labels, model_4_pred)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-etkKE_Mta5",
        "outputId": "5610485f-b06e-44cf-8578-6a0a618e575e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.24671916010499,\n",
              " 'precision': 77.02265372168284,\n",
              " 'recall': 68.39080459770115,\n",
              " 'f1_score': 72.45053272450532}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5 - Conv1D\n",
        "\n",
        "Typical structure:\n",
        "\n",
        "Inputs(text) -> Tokenization -> Embedding -> Layers (Conv1D + Pooling) -> Outputs (class probabilities)"
      ],
      "metadata": {
        "id": "28MjuCgSOf0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build using functional API\n",
        "inputs=tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(f\"Shape after embedding: {x.shape}\")\n",
        "x = tf.keras.layers.Conv1D(filters=64, # number of hidden units\n",
        "                           kernel_size=5, # look at 5 words at a time\n",
        "                           strides=1,\n",
        "                           activation=\"relu\",\n",
        "                           padding=\"valid\")(x) # padding is often necessary when the kernel extends beyond the activation map. valid means output is smaller than input shape.  same means output is same as input shape.\n",
        "print(f\"Shape after conv1D: {x.shape}\")\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x) # condenses the max value from all 15 tokens to 1 value. equivalent to \"get the most important features\" or \"get the feature with the highest value\"\n",
        "print(f\"Shape after maxpool: {x.shape}\")\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "print(f\"Shape after dense: {outputs.shape}\")\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1D\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNM2xKGqQAIY",
        "outputId": "d533fc6a-8a29-4af5-9fe1-ecced619faea"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after embedding: (None, 15, 128)\n",
            "Shape after conv1D: (None, 11, 64)\n",
            "Shape after maxpool: (None, 64)\n",
            "Shape after dense: (None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model summary\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEtxwC-OZaWF",
        "outputId": "25de7e21-307d-4a8f-e5b7-6d586589e468"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "czZxYCVGafff"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_5_conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I86D7IGaizz",
        "outputId": "7187f494-7096-4f62-ad4d-ca37727b8be7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_conv1D/20230126-234214\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 1.0656 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0530 - accuracy: 0.9791 - val_loss: 1.1514 - val_accuracy: 0.7651\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0503 - accuracy: 0.9788 - val_loss: 1.2140 - val_accuracy: 0.7546\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0467 - accuracy: 0.9803 - val_loss: 1.2362 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0464 - accuracy: 0.9791 - val_loss: 1.2694 - val_accuracy: 0.7467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the predictions\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "id": "cszJtriYakfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs to labels\n",
        "model_5_pred = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_pred[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YbZyo7Xb4yg",
        "outputId": "23b786e2-5ff5-4cea-dcac-ccc2808c6dbf"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results\n",
        "model_5_results = calculate_results(val_labels, model_5_pred)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcg9KtbocBA7",
        "outputId": "13a34b1e-b270-4af4-a5d0-63d948ab0f64"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 76.11464968152866,\n",
              " 'recall': 68.67816091954023,\n",
              " 'f1_score': 72.20543806646526}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 6 - Tensorflow Hub Pretrained Sentence Encoder"
      ],
      "metadata": {
        "id": "k572ekndjsjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([\"There's a flood in my street!\",\n",
        "                       \"when you call the universal sentence encoder on a sentence, it turns it into numbers\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwEfB7HWkHiG",
        "outputId": "39c74ce5-0729-4283-9998-9ca0dabde52a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157025  0.02485911  0.02878051 -0.012715    0.03971541  0.08827761\n",
            "  0.02680988  0.05589838 -0.01068731 -0.00597293  0.00639321 -0.01819516\n",
            "  0.00030816  0.09105889  0.05874645 -0.03180629  0.01512474 -0.05162925\n",
            "  0.00991366 -0.06865345 -0.04209306  0.0267898   0.03011009  0.00321065\n",
            " -0.00337968 -0.04787356  0.0226672  -0.00985927 -0.04063615 -0.01292093\n",
            " -0.04666382  0.05630299 -0.03949255  0.00517682  0.02495827 -0.07014439\n",
            "  0.0287151   0.0494768  -0.00633978 -0.08960193  0.02807119 -0.00808364\n",
            " -0.01360601  0.05998649 -0.10361788 -0.05195372  0.00232958 -0.02332531\n",
            " -0.03758106  0.03327729], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_samples.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N1Tj-W1lQNR",
        "outputId": "e5d8bdbb-2305-45ca-ad8a-19bf1965429e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ]
}